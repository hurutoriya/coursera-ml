{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week3 Programming Assignment: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%plot -f png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex2.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting data with + indicating (y = 1) examples and o indicating (y = 0) examples.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGkCAIAAACgjIjwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA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\nhmUVwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%% Machine Learning Online Class - Exercise 2: Logistic Regression\n",
    "%\n",
    "%  Instructions\n",
    "%  ------------\n",
    "% \n",
    "%  This file contains code that helps you get started on the logistic\n",
    "%  regression exercise. You will need to complete the following functions \n",
    "%  in this exericse:\n",
    "%\n",
    "%     sigmoid.m\n",
    "%     costFunction.m\n",
    "%     predict.m\n",
    "%     costFunctionReg.m\n",
    "%\n",
    "%  For this exercise, you will not need to change any code in this file,\n",
    "%  or any other files other than those mentioned above.\n",
    "%\n",
    "\n",
    "%% Initialization\n",
    "clear ; close all; clc\n",
    "\n",
    "%% Load Data\n",
    "%  The first two columns contains the exam scores and the third column\n",
    "%  contains the label.\n",
    "\n",
    "data = load('ex2data1.txt');\n",
    "X = data(:, [1, 2]); y = data(:, 3);\n",
    "\n",
    "%% ==================== Part 1: Plotting ====================\n",
    "%  We start the exercise by first plotting the data to understand the \n",
    "%  the problem we are working with.\n",
    "\n",
    "fprintf(['Plotting data with + indicating (y = 1) examples and o ' ...\n",
    "         'indicating (y = 0) examples.\\n']);\n",
    "\n",
    "plot(X, y, 'rx', 'MarkerSize', 10);\n",
    "\n",
    "pos = find(y==1); neg = find(y == 0);\n",
    "plot(X(pos, 1), X(pos, 2), 'k+','LineWidth', 2,  'MarkerSize', 7);\n",
    "hold on;\n",
    "plot(X(neg, 1), X(neg, 2), 'ko', 'MarkerFaceColor', 'y', 'MarkerSize', 7)\n",
    "\n",
    "% Put some labels \n",
    "hold on;\n",
    "% Labels and Legend\n",
    "xlabel('Exam 1 score')\n",
    "ylabel('Exam 2 score')\n",
    "\n",
    "% Specified in plot order\n",
    "legend('Admitted', 'Not admitted')\n",
    "hold off;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g =\n",
      "\n",
      "   0.50000\n",
      "   0.50000\n",
      "\n",
      "ans =\n",
      "\n",
      "   0.50000\n",
      "   0.50000\n",
      "\n",
      "z =\n",
      "\n",
      "   0\n",
      "   0\n",
      "\n",
      "hoge =\n",
      "\n",
      "   0.50000\n",
      "   0.50000\n",
      "\n",
      "z =\n",
      "\n",
      "   0\n",
      "   0\n",
      "\n",
      "hoge =\n",
      "\n",
      "   0.25000   0.25000\n",
      "\n",
      "ans =\n",
      "\n",
      "   0.16667   0.16667   0.16667\n",
      "\n",
      "ans =\n",
      "\n",
      "   0.50000\n",
      "   0.50000\n",
      "   0.50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "function g = sigmoid(z)\n",
    "%SIGMOID Compute sigmoid function\n",
    "%   g = SIGMOID(z) computes the sigmoid of z.\n",
    "\n",
    "% You need to return the following variables correctly\n",
    "g = zeros(size(z));\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the sigmoid of each value of z (z can be a matrix,\n",
    "%               vector or scalar).\n",
    "\n",
    "g = 1./(1+exp(-z))\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "end\n",
    "sigmoid([0;0])\n",
    "\n",
    "z = ([0;0])\n",
    "hoge = 1./(1+exp(-z))\n",
    "\n",
    "z = ([0;0])\n",
    "hoge = 1/(1+exp(-z))\n",
    "\n",
    "% All element manipulation vs \n",
    "1/([2;2;2])\n",
    "1./([2;2;2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X =\n",
      "\n",
      "    1.0000    1.0000    1.0000   34.6237   78.0247\n",
      "    1.0000    1.0000    1.0000   30.2867   43.8950\n",
      "    1.0000    1.0000    1.0000   35.8474   72.9022\n",
      "    1.0000    1.0000    1.0000   60.1826   86.3086\n",
      "    1.0000    1.0000    1.0000   79.0327   75.3444\n",
      "    1.0000    1.0000    1.0000   45.0833   56.3164\n",
      "    1.0000    1.0000    1.0000   61.1067   96.5114\n",
      "    1.0000    1.0000    1.0000   75.0247   46.5540\n",
      "    1.0000    1.0000    1.0000   76.0988   87.4206\n",
      "    1.0000    1.0000    1.0000   84.4328   43.5334\n",
      "    1.0000    1.0000    1.0000   95.8616   38.2253\n",
      "    1.0000    1.0000    1.0000   75.0137   30.6033\n",
      "    1.0000    1.0000    1.0000   82.3071   76.4820\n",
      "    1.0000    1.0000    1.0000   69.3646   97.7187\n",
      "    1.0000    1.0000    1.0000   39.5383   76.0368\n",
      "    1.0000    1.0000    1.0000   53.9711   89.2074\n",
      "    1.0000    1.0000    1.0000   69.0701   52.7405\n",
      "    1.0000    1.0000    1.0000   67.9469   46.6786\n",
      "    1.0000    1.0000    1.0000   70.6615   92.9271\n",
      "    1.0000    1.0000    1.0000   76.9788   47.5760\n",
      "    1.0000    1.0000    1.0000   67.3720   42.8384\n",
      "    1.0000    1.0000    1.0000   89.6768   65.7994\n",
      "    1.0000    1.0000    1.0000   50.5348   48.8558\n",
      "    1.0000    1.0000    1.0000   34.2121   44.2095\n",
      "    1.0000    1.0000    1.0000   77.9241   68.9724\n",
      "    1.0000    1.0000    1.0000   62.2710   69.9545\n",
      "    1.0000    1.0000    1.0000   80.1902   44.8216\n",
      "    1.0000    1.0000    1.0000   93.1144   38.8007\n",
      "    1.0000    1.0000    1.0000   61.8302   50.2561\n",
      "    1.0000    1.0000    1.0000   38.7858   64.9957\n",
      "    1.0000    1.0000    1.0000   61.3793   72.8079\n",
      "    1.0000    1.0000    1.0000   85.4045   57.0520\n",
      "    1.0000    1.0000    1.0000   52.1080   63.1276\n",
      "    1.0000    1.0000    1.0000   52.0454   69.4329\n",
      "    1.0000    1.0000    1.0000   40.2369   71.1677\n",
      "    1.0000    1.0000    1.0000   54.6351   52.2139\n",
      "    1.0000    1.0000    1.0000   33.9155   98.8694\n",
      "    1.0000    1.0000    1.0000   64.1770   80.9081\n",
      "    1.0000    1.0000    1.0000   74.7893   41.5734\n",
      "    1.0000    1.0000    1.0000   34.1836   75.2377\n",
      "    1.0000    1.0000    1.0000   83.9024   56.3080\n",
      "    1.0000    1.0000    1.0000   51.5477   46.8563\n",
      "    1.0000    1.0000    1.0000   94.4434   65.5689\n",
      "    1.0000    1.0000    1.0000   82.3688   40.6183\n",
      "    1.0000    1.0000    1.0000   51.0478   45.8227\n",
      "    1.0000    1.0000    1.0000   62.2227   52.0610\n",
      "    1.0000    1.0000    1.0000   77.1930   70.4582\n",
      "    1.0000    1.0000    1.0000   97.7716   86.7278\n",
      "    1.0000    1.0000    1.0000   62.0731   96.7688\n",
      "    1.0000    1.0000    1.0000   91.5650   88.6963\n",
      "    1.0000    1.0000    1.0000   79.9448   74.1631\n",
      "    1.0000    1.0000    1.0000   99.2725   60.9990\n",
      "    1.0000    1.0000    1.0000   90.5467   43.3906\n",
      "    1.0000    1.0000    1.0000   34.5245   60.3963\n",
      "    1.0000    1.0000    1.0000   50.2865   49.8045\n",
      "    1.0000    1.0000    1.0000   49.5867   59.8090\n",
      "    1.0000    1.0000    1.0000   97.6456   68.8616\n",
      "    1.0000    1.0000    1.0000   32.5772   95.5985\n",
      "    1.0000    1.0000    1.0000   74.2487   69.8246\n",
      "    1.0000    1.0000    1.0000   71.7965   78.4536\n",
      "    1.0000    1.0000    1.0000   75.3956   85.7599\n",
      "    1.0000    1.0000    1.0000   35.2861   47.0205\n",
      "    1.0000    1.0000    1.0000   56.2538   39.2615\n",
      "    1.0000    1.0000    1.0000   30.0588   49.5930\n",
      "    1.0000    1.0000    1.0000   44.6683   66.4501\n",
      "    1.0000    1.0000    1.0000   66.5609   41.0921\n",
      "    1.0000    1.0000    1.0000   40.4576   97.5352\n",
      "    1.0000    1.0000    1.0000   49.0726   51.8832\n",
      "    1.0000    1.0000    1.0000   80.2796   92.1161\n",
      "    1.0000    1.0000    1.0000   66.7467   60.9914\n",
      "    1.0000    1.0000    1.0000   32.7228   43.3072\n",
      "    1.0000    1.0000    1.0000   64.0393   78.0317\n",
      "    1.0000    1.0000    1.0000   72.3465   96.2276\n",
      "    1.0000    1.0000    1.0000   60.4579   73.0950\n",
      "    1.0000    1.0000    1.0000   58.8410   75.8584\n",
      "    1.0000    1.0000    1.0000   99.8279   72.3693\n",
      "    1.0000    1.0000    1.0000   47.2643   88.4759\n",
      "    1.0000    1.0000    1.0000   50.4582   75.8099\n",
      "    1.0000    1.0000    1.0000   60.4556   42.5084\n",
      "    1.0000    1.0000    1.0000   82.2267   42.7199\n",
      "    1.0000    1.0000    1.0000   88.9139   69.8038\n",
      "    1.0000    1.0000    1.0000   94.8345   45.6943\n",
      "    1.0000    1.0000    1.0000   67.3193   66.5894\n",
      "    1.0000    1.0000    1.0000   57.2387   59.5143\n",
      "    1.0000    1.0000    1.0000   80.3668   90.9601\n",
      "    1.0000    1.0000    1.0000   68.4685   85.5943\n",
      "    1.0000    1.0000    1.0000   42.0755   78.8448\n",
      "    1.0000    1.0000    1.0000   75.4777   90.4245\n",
      "    1.0000    1.0000    1.0000   78.6354   96.6474\n",
      "    1.0000    1.0000    1.0000   52.3480   60.7695\n",
      "    1.0000    1.0000    1.0000   94.0943   77.1591\n",
      "    1.0000    1.0000    1.0000   90.4486   87.5088\n",
      "    1.0000    1.0000    1.0000   55.4822   35.5707\n",
      "    1.0000    1.0000    1.0000   74.4927   84.8451\n",
      "    1.0000    1.0000    1.0000   89.8458   45.3583\n",
      "    1.0000    1.0000    1.0000   83.4892   48.3803\n",
      "    1.0000    1.0000    1.0000   42.2617   87.1039\n",
      "    1.0000    1.0000    1.0000   99.3150   68.7754\n",
      "    1.0000    1.0000    1.0000   55.3400   64.9319\n",
      "    1.0000    1.0000    1.0000   74.7759   89.5298\n",
      "\n",
      "initial_theta =\n",
      "\n",
      "   0\n",
      "   0\n",
      "   0\n",
      "   0\n",
      "   0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%% ============ Part 2: Compute Cost and Gradient ============\n",
    "%  In this part of the exercise, you will implement the cost and gradient\n",
    "%  for logistic regression. You neeed to complete the code in \n",
    "%  costFunction.m\n",
    "\n",
    "%  Setup the data matrix appropriately, and add ones for the intercept term\n",
    "[m, n] = size(X);\n",
    "\n",
    "% Add intercept term to x and X_test\n",
    "X = [ones(m, 1) X]\n",
    "\n",
    "% Initialize fitting parameters\n",
    "initial_theta = zeros(n + 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function [J, grad] = costFunction(theta, X, y)\n",
    "%COSTFUNCTION Compute cost and gradient for logistic regression\n",
    "%   J = COSTFUNCTION(theta, X, y) computes the cost of using theta as the\n",
    "%   parameter for logistic regression and the gradient of the cost\n",
    "%   w.r.t. to the parameters.\n",
    "\n",
    "% Initialize some useful values\n",
    "m = length(y); % number of training examples\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "J = 0;\n",
    "grad = zeros(size(theta));\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the cost of a particular choice of theta.\n",
    "%               You should set J to the cost.\n",
    "%               Compute the partial derivatives and set grad to the partial\n",
    "%               derivatives of the cost w.r.t. each parameter in theta\n",
    "%\n",
    "% Note: grad should have the same dimensions as theta\n",
    "%\n",
    "\n",
    "h = theta'X)\n",
    "J = 1/m*sum((1-y)log(1-sigmoid()))\n",
    "grad = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% Compute and display initial cost and gradient\n",
    "[cost, grad] = costFunction(initial_theta, X, y);\n",
    "\n",
    "fprintf('Cost at initial theta (zeros): %f\\n', cost);\n",
    "fprintf('Expected cost (approx): 0.693\\n');\n",
    "fprintf('Gradient at initial theta (zeros): \\n');\n",
    "fprintf(' %f \\n', grad);\n",
    "fprintf('Expected gradients (approx):\\n -0.1000\\n -12.0092\\n -11.2628\\n');\n",
    "\n",
    "% Compute and display cost and gradient with non-zero theta\n",
    "test_theta = [-24; 0.2; 0.2];\n",
    "[cost, grad] = costFunction(test_theta, X, y);\n",
    "\n",
    "fprintf('\\nCost at test theta: %f\\n', cost);\n",
    "fprintf('Expected cost (approx): 0.218\\n');\n",
    "fprintf('Gradient at test theta: \\n');\n",
    "fprintf(' %f \\n', grad);\n",
    "fprintf('Expected gradients (approx):\\n 0.043\\n 2.566\\n 2.647\\n');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%% ============= Part 3: Optimizing using fminunc  =============\n",
    "%  In this exercise, you will use a built-in function (fminunc) to find the\n",
    "%  optimal parameters theta.\n",
    "\n",
    "%  Set options for fminunc\n",
    "options = optimset('GradObj', 'on', 'MaxIter', 400);\n",
    "\n",
    "%  Run fminunc to obtain the optimal theta\n",
    "%  This function will return theta and the cost \n",
    "[theta, cost] = ...\n",
    "\tfminunc(@(t)(costFunction(t, X, y)), initial_theta, options);\n",
    "\n",
    "% Print theta to screen\n",
    "fprintf('Cost at theta found by fminunc: %f\\n', cost);\n",
    "fprintf('Expected cost (approx): 0.203\\n');\n",
    "fprintf('theta: \\n');\n",
    "fprintf(' %f \\n', theta);\n",
    "fprintf('Expected theta (approx):\\n');\n",
    "fprintf(' -25.161\\n 0.206\\n 0.201\\n');\n",
    "\n",
    "% Plot Boundary\n",
    "plotDecisionBoundary(theta, X, y);\n",
    "\n",
    "% Put some labels \n",
    "hold on;\n",
    "% Labels and Legend\n",
    "xlabel('Exam 1 score')\n",
    "ylabel('Exam 2 score')\n",
    "\n",
    "% Specified in plot order\n",
    "legend('Admitted', 'Not admitted')\n",
    "hold off;\n",
    "\n",
    "fprintf('\\nProgram paused. Press enter to continue.\\n');\n",
    "pause;\n",
    "\n",
    "%% ============== Part 4: Predict and Accuracies ==============\n",
    "%  After learning the parameters, you'll like to use it to predict the outcomes\n",
    "%  on unseen data. In this part, you will use the logistic regression model\n",
    "%  to predict the probability that a student with score 45 on exam 1 and \n",
    "%  score 85 on exam 2 will be admitted.\n",
    "%\n",
    "%  Furthermore, you will compute the training and test set accuracies of \n",
    "%  our model.\n",
    "%\n",
    "%  Your task is to complete the code in predict.m\n",
    "\n",
    "%  Predict probability for a student with score 45 on exam 1 \n",
    "%  and score 85 on exam 2 \n",
    "\n",
    "prob = sigmoid([1 45 85] * theta);\n",
    "fprintf(['For a student with scores 45 and 85, we predict an admission ' ...\n",
    "         'probability of %f\\n'], prob);\n",
    "fprintf('Expected value: 0.775 +/- 0.002\\n\\n');\n",
    "\n",
    "% Compute accuracy on our training set\n",
    "p = predict(theta, X);\n",
    "\n",
    "fprintf('Train Accuracy: %f\\n', mean(double(p == y)) * 100);\n",
    "fprintf('Expected accuracy (approx): 89.0\\n');\n",
    "fprintf('\\n');\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
